{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0ed3dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from typing import List, Dict, Optional\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf34f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OFIAnalyzer:\n",
    "    \"\"\"\n",
    "    Enhanced Order Flow Imbalance analyzer with improved efficiency and robustness.\n",
    "    \n",
    "    Features:\n",
    "    - Type hints for better code clarity\n",
    "    - More efficient memory usage\n",
    "    - Better handling of edge cases\n",
    "    - Additional validation checks\n",
    "    - Optimized calculations\n",
    "    - More detailed documentation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data: pd.DataFrame, levels: int = 10, time_window: str = '1min'):\n",
    "        \"\"\"\n",
    "        Initialize the OFI analyzer with order book data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        data : pd.DataFrame\n",
    "            Order book data containing bid/ask prices and sizes\n",
    "        levels : int, optional\n",
    "            Number of order book levels to consider (default: 10)\n",
    "        time_window : str, optional\n",
    "            Time window for aggregating OFI (default: '1min')\n",
    "            \n",
    "        Raises:\n",
    "        -------\n",
    "        ValueError\n",
    "            If required columns are missing from the input data\n",
    "        \"\"\"\n",
    "        # Validate input data\n",
    "        required_columns = ['ts_event', 'symbol', 'bid_px_00', 'ask_px_00']\n",
    "        if not all(col in data.columns for col in required_columns):\n",
    "            raise ValueError(f\"Input data must contain these columns: {required_columns}\")\n",
    "            \n",
    "        self.data = data.copy()\n",
    "        self.levels = min(levels, 10)  # Ensure we don't exceed available levels\n",
    "        self.time_window = time_window\n",
    "        self.symbols = data['symbol'].unique()\n",
    "        self._validate_data()\n",
    "        self._preprocess_data()\n",
    "        \n",
    "    def _validate_data(self) -> None:\n",
    "        \"\"\"Validate the input data structure.\"\"\"\n",
    "        # Check that all required level columns exist\n",
    "        for level in range(self.levels):\n",
    "            for prefix in ['bid_px_', 'ask_px_', 'bid_sz_', 'ask_sz_']:\n",
    "                col = f\"{prefix}{level:02d}\"\n",
    "                if col not in self.data.columns:\n",
    "                    raise ValueError(f\"Missing required column: {col}\")\n",
    "    \n",
    "    def _preprocess_data(self) -> None:\n",
    "        \"\"\"Pre-process the order book data for OFI calculations.\"\"\"\n",
    "        # Convert timestamps and sort\n",
    "        self.data['ts_event'] = pd.to_datetime(self.data['ts_event'])\n",
    "        self.data['ts_recv'] = pd.to_datetime(self.data['ts_recv'])\n",
    "        self.data = self.data.sort_values('ts_event')\n",
    "        \n",
    "        # Calculate mid-price and create time bins\n",
    "        self.data['mid_price'] = (self.data['bid_px_00'] + self.data['ask_px_00']) / 2\n",
    "        self.data['time_bin'] = self.data['ts_event'].dt.floor(self.time_window)\n",
    "        \n",
    "    def _calculate_single_level_ofi(self, level: int) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Calculate OFI for a single level using vectorized operations.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        level : int\n",
    "            Order book level to calculate OFI for\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        pd.Series\n",
    "            OFI values for the specified level\n",
    "        \"\"\"\n",
    "        # Get column names for this level\n",
    "        bid_px_col = f'bid_px_{level:02d}'\n",
    "        ask_px_col = f'ask_px_{level:02d}'\n",
    "        bid_sz_col = f'bid_sz_{level:02d}'\n",
    "        ask_sz_col = f'ask_sz_{level:02d}'\n",
    "        \n",
    "        # Group by symbol to handle each asset separately\n",
    "        grouped = self.data.groupby('symbol')\n",
    "        \n",
    "        # Calculate price and size changes using vectorized operations\n",
    "        bid_px_change = grouped[bid_px_col].diff()\n",
    "        ask_px_change = grouped[ask_px_col].diff()\n",
    "        bid_sz_change = grouped[bid_sz_col].diff()\n",
    "        ask_sz_change = grouped[ask_sz_col].diff()\n",
    "        \n",
    "        # Calculate bid OFI component\n",
    "        bid_ofi = (\n",
    "            (bid_px_change > 0) * self.data[bid_sz_col] - \n",
    "            (bid_px_change < 0) * self.data[bid_sz_col] + \n",
    "            (bid_px_change == 0) * bid_sz_change.fillna(0)\n",
    "        )\n",
    "        \n",
    "        # Calculate ask OFI component\n",
    "        ask_ofi = (\n",
    "            (ask_px_change > 0) * (-self.data[ask_sz_col]) - \n",
    "            (ask_px_change < 0) * self.data[ask_sz_col] + \n",
    "            (ask_px_change == 0) * ask_sz_change.fillna(0)\n",
    "        )\n",
    "        \n",
    "        return bid_ofi + ask_ofi\n",
    "    \n",
    "    def calculate_best_level_ofi(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate Best-Level OFI (level 0) and aggregate by time window.\"\"\"\n",
    "        self.data['best_level_ofi'] = self._calculate_single_level_ofi(0)\n",
    "        \n",
    "        # Aggregate using sum (as per Cont et al.)\n",
    "        result = (self.data.groupby(['time_bin', 'symbol'])['best_level_ofi']\n",
    "                 .sum()\n",
    "                 .unstack(fill_value=0)\n",
    "                 .reset_index()\n",
    "                 .rename(columns={'time_bin': 'timestamp'}))\n",
    "        \n",
    "        # For single asset, keep consistent column naming\n",
    "        if len(self.symbols) == 1:\n",
    "            result = result.rename(columns={self.symbols[0]: 'OFI_best'})\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def calculate_multi_level_ofi(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate Multi-Level OFI by aggregating across all levels.\"\"\"\n",
    "        # Calculate OFI for each level and aggregate\n",
    "        ofi_values = np.zeros(len(self.data))\n",
    "        \n",
    "        for level in range(self.levels):\n",
    "            ofi_values += self._calculate_single_level_ofi(level)\n",
    "        \n",
    "        self.data['multi_level_ofi'] = ofi_values\n",
    "        \n",
    "        # Calculate average depth for scaling\n",
    "        depth_values = np.zeros(len(self.data))\n",
    "        for level in range(self.levels):\n",
    "            bid_col = f'bid_sz_{level:02d}'\n",
    "            ask_col = f'ask_sz_{level:02d}'\n",
    "            depth_values += (self.data[bid_col] + self.data[ask_col]) / 2\n",
    "        \n",
    "        avg_depth = depth_values / self.levels\n",
    "        self.data['multi_level_ofi'] = self.data['multi_level_ofi'] / avg_depth.replace(0, 1)\n",
    "        \n",
    "        # Aggregate results\n",
    "        result = (self.data.groupby(['time_bin', 'symbol'])['multi_level_ofi']\n",
    "                 .sum()\n",
    "                 .unstack(fill_value=0)\n",
    "                 .reset_index()\n",
    "                 .rename(columns={'time_bin': 'timestamp'}))\n",
    "        \n",
    "        # Sum across levels and rename columns\n",
    "        result['OFI_multi'] = result[self.symbols].sum(axis=1) if len(self.symbols) > 1 else result[self.symbols[0]]\n",
    "        \n",
    "        return result[['timestamp', 'OFI_multi'] + list(self.symbols)]\n",
    "    \n",
    "    def calculate_integrated_ofi(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate Integrated OFI using PCA on multi-level OFI.\"\"\"\n",
    "        # First calculate multi-level OFI for each level\n",
    "        ofi_matrix = []\n",
    "        for level in range(self.levels):\n",
    "            ofi_matrix.append(self._calculate_single_level_ofi(level))\n",
    "        \n",
    "        ofi_matrix = pd.concat(ofi_matrix, axis=1)\n",
    "        ofi_matrix.columns = [f'ofi_{level}' for level in range(self.levels)]\n",
    "        \n",
    "        # Standardize and apply PCA\n",
    "        scaler = StandardScaler()\n",
    "        pca = PCA(n_components=1)\n",
    "        \n",
    "        # Group by time bin and symbol\n",
    "        grouped = pd.concat([self.data[['time_bin', 'symbol']], ofi_matrix], axis=1)\n",
    "        grouped = grouped.groupby(['time_bin', 'symbol']).sum()\n",
    "        \n",
    "        # Apply PCA to each symbol's data\n",
    "        results = []\n",
    "        for symbol in self.symbols:\n",
    "            symbol_data = grouped.xs(symbol, level='symbol')\n",
    "            if len(symbol_data) < 2:\n",
    "                warnings.warn(f\"Not enough data points for PCA for symbol {symbol}\")\n",
    "                continue\n",
    "                \n",
    "            ofi_scaled = scaler.fit_transform(symbol_data)\n",
    "            integrated_ofi = pca.fit_transform(ofi_scaled)\n",
    "            \n",
    "            # Normalize by L1 norm of weights\n",
    "            weights = pca.components_[0]\n",
    "            l1_norm = np.sum(np.abs(weights))\n",
    "            integrated_ofi = integrated_ofi / l1_norm\n",
    "            \n",
    "            result = pd.DataFrame({\n",
    "                'timestamp': symbol_data.index,\n",
    "                'symbol': symbol,\n",
    "                'OFI_integrated': integrated_ofi.flatten()\n",
    "            })\n",
    "            results.append(result)\n",
    "        \n",
    "        if not results:\n",
    "            return pd.DataFrame(columns=['timestamp', 'OFI_integrated'])\n",
    "            \n",
    "        return pd.concat(results).reset_index(drop=True)\n",
    "    \n",
    "    def calculate_cross_asset_ofi(self, alpha: float = 0.1) -> pd.DataFrame:\n",
    "        \"\"\"Calculate Cross-Asset OFI using LASSO regression.\"\"\"\n",
    "        if len(self.symbols) < 2:\n",
    "            warnings.warn(\"Insufficient assets for cross-asset OFI calculation\")\n",
    "            result = self.calculate_best_level_ofi()[['timestamp']].copy()\n",
    "            result['OFI_cross'] = np.nan\n",
    "            return result\n",
    "        \n",
    "        # Calculate best-level OFI for each asset\n",
    "        asset_ofis = []\n",
    "        for symbol in self.symbols:\n",
    "            symbol_data = self.data[self.data['symbol'] == symbol].copy()\n",
    "            symbol_data['ofi'] = self._calculate_single_level_ofi(0)\n",
    "            \n",
    "            ofi_ts = symbol_data.groupby('time_bin')['ofi'].sum().reset_index()\n",
    "            ofi_ts = ofi_ts.rename(columns={'ofi': symbol})\n",
    "            asset_ofis.append(ofi_ts)\n",
    "        \n",
    "        # Merge all assets' OFI\n",
    "        ofi_matrix = asset_ofis[0]\n",
    "        for df in asset_ofis[1:]:\n",
    "            ofi_matrix = ofi_matrix.merge(df, on='time_bin', how='outer')\n",
    "        ofi_matrix = ofi_matrix.fillna(0).sort_values('time_bin')\n",
    "        \n",
    "        # Calculate cross-impact using LASSO\n",
    "        cross_results = []\n",
    "        for target in self.symbols:\n",
    "            X = ofi_matrix.drop(columns=['time_bin', target])\n",
    "            y = ofi_matrix[target]\n",
    "            \n",
    "            if len(X) < 10:  # Minimum samples for meaningful regression\n",
    "                cross_impact = np.zeros(len(X))\n",
    "            else:\n",
    "                lasso = Lasso(alpha=alpha, max_iter=10000, random_state=42)\n",
    "                lasso.fit(X, y)\n",
    "                cross_impact = X @ lasso.coef_\n",
    "            \n",
    "            cross_results.append(pd.DataFrame({\n",
    "                'timestamp': ofi_matrix['time_bin'],\n",
    "                'symbol': target,\n",
    "                'cross_ofi': cross_impact\n",
    "            }))\n",
    "        \n",
    "        # Combine results\n",
    "        cross_ofi = pd.concat(cross_results)\n",
    "        cross_ofi = cross_ofi.groupby('timestamp')['cross_ofi'].mean().reset_index()\n",
    "        cross_ofi = cross_ofi.rename(columns={'cross_ofi': 'OFI_cross'})\n",
    "        \n",
    "        return cross_ofi\n",
    "    \n",
    "    def calculate_all_features(self) -> pd.DataFrame:\n",
    "        \"\"\"Calculate all OFI features and combine into a single DataFrame.\"\"\"\n",
    "        features = [\n",
    "            self.calculate_best_level_ofi(),\n",
    "            self.calculate_multi_level_ofi()[['timestamp', 'OFI_multi']],\n",
    "            self.calculate_integrated_ofi(),\n",
    "            self.calculate_cross_asset_ofi()\n",
    "        ]\n",
    "        \n",
    "        # Merge all features\n",
    "        result = features[0]\n",
    "        for df in features[1:]:\n",
    "            if not df.empty:\n",
    "                result = result.merge(df, on='timestamp', how='left')\n",
    "        \n",
    "        # Fill NaN with 0 (except for cross-asset OFI which might be intentionally NaN)\n",
    "        for col in result.columns:\n",
    "            if col not in ['timestamp', 'symbol', 'OFI_cross']:\n",
    "                result[col] = result[col].fillna(0)\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8fb2b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    try:\n",
    "        # Load and process data\n",
    "        data = pd.read_csv('first_25000_rows.csv')\n",
    "        analyzer = OFIAnalyzer(data, time_window='1min')\n",
    "        \n",
    "        # Calculate features\n",
    "        features = analyzer.calculate_all_features()\n",
    "        \n",
    "        # Save and display results\n",
    "        features.to_csv('enhanced_ofi_features-task-1.csv', index=False)\n",
    "        print(\"Enhanced OFI features calculated and saved to enhanced_ofi_features.csv\")\n",
    "        print(\"\\nSample results:\")\n",
    "        print(features.head())\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing data: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ddfeaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced OFI features calculated and saved to enhanced_ofi_features.csv\n",
      "\n",
      "Sample results:\n",
      "                  timestamp  OFI_best   OFI_multi symbol  OFI_integrated  \\\n",
      "0 2024-10-21 11:54:00+00:00    -533.0  -34.960958   AAPL       -0.640427   \n",
      "1 2024-10-21 11:55:00+00:00   -1621.0  -84.327239   AAPL       -0.493726   \n",
      "2 2024-10-21 11:56:00+00:00    -468.0  -67.501703   AAPL       -0.508024   \n",
      "3 2024-10-21 11:57:00+00:00    -482.0 -133.390723   AAPL       -0.344030   \n",
      "4 2024-10-21 11:58:00+00:00    -224.0 -223.095515   AAPL       -0.065161   \n",
      "\n",
      "   OFI_cross  \n",
      "0        NaN  \n",
      "1        NaN  \n",
      "2        NaN  \n",
      "3        NaN  \n",
      "4        NaN  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/mc/l4_t7brd2v3cy_nrw6jzyjf40000gn/T/ipykernel_47403/2174729248.py:207: UserWarning: Insufficient assets for cross-asset OFI calculation\n",
      "  warnings.warn(\"Insufficient assets for cross-asset OFI calculation\")\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
